# RF-FilterLLM 技术深度解读

> **目标受众**：零基础读者。读完本文后，即使你从未听说过"切比雪夫滤波器"，也能理解本论文做了什么、为什么这样做、以及它的价值所在。

---

## 目录

1. [背景知识：滤波器是什么？](#1-背景知识滤波器是什么)
2. [系统总体架构](#2-系统总体架构)
3. [数据引擎：训练数据如何构建](#3-数据引擎训练数据如何构建)
4. [三大数据增强管线](#4-三大数据增强管线)
5. [微调训练：QLoRA 技术详解](#5-微调训练qlora-技术详解)
6. [闭环智能体：LLM + 仿真器协作](#6-闭环智能体llm--仿真器协作)
7. [实验结果](#7-实验结果)
8. [核心哲学：为什么不让 LLM 直接预测 LC 值？](#8-核心哲学为什么不让-llm-直接预测-lc-值)
9. [论文价值与意义](#9-论文价值与意义)

---

## 1. 背景知识：滤波器是什么？

### 1.1 生活中的滤波器

想象你在嘈杂的咖啡厅里打电话，你的手机需要从一堆无线信号中准确地挑出属于你的通话频率——这就是滤波器在做的事。

**滤波器（Filter）** 是一种电子元件，它允许某些频率的信号通过，同时阻挡其他频率的信号。就像一个"信号筛子"。

### 1.2 滤波器的三种基本类型

| 类型 | 英文缩写 | 功能 | 生活类比 |
|------|----------|------|----------|
| 低通滤波器 | LPF | 让低频通过，阻挡高频 | 只听低音，屏蔽高音 |
| 高通滤波器 | HPF | 让高频通过，阻挡低频 | 只听高音，屏蔽低音 |
| 带通滤波器 | BPF | 只让某个范围的频率通过 | 只听中音，屏蔽高低音 |

### 1.3 切比雪夫滤波器

切比雪夫（Chebyshev）滤波器是众多滤波器设计方法中的一种，它的特点是：

- **优点**：在通带（允许通过的频率范围）到阻带（被阻挡的频率范围）之间的过渡非常陡峭，也就是"分选能力"很强。
- **代价**：通带内会有一些小的波纹（ripple），即信号强度会有微小的起伏。

用一个比喻：如果普通滤波器像一把普通的刀切蛋糕（切口不够整齐），切比雪夫滤波器就像一把更锋利的刀（切口很齐整，但刀身上有几个小缺口）。

### 1.4 滤波器的核心参数

设计一个切比雪夫滤波器需要指定以下参数：

| 参数 | 含义 | 单位 |
|------|------|------|
| **阶数 N (order)** | 滤波器的"复杂度" — 阶数越高，过渡越陡峭，但电路越复杂 | 无 |
| **纹波 (ripple_db)** | 通带内允许的信号强度波动幅度 | dB |
| **截止频率 fc** | 通带的边界频率 | GHz |
| **阻带频率 fs** | 阻带的起始频率 | GHz |
| **阻带衰减 La** | 在阻带中信号被削弱多少 | dB |
| **特征阻抗 R0** | 电路的参考阻抗，通常为 50Ω | Ω |

> **关键洞察**：阶数 N 是最核心的参数。一旦确定了 N，滤波器的所有 L（电感）和 C（电容）元件值都可以通过数学公式精确计算出来。这也是本论文的核心设计哲学——让 LLM 来判断 N 应该是多少。

### 1.5 从阶数到元件值：gk 原型综合

这一步是纯数学计算，不需要任何"智能"。完整推导过程如下：

---

**Step 1** — 计算两个中间量 β 和 γ（只与纹波和阶数有关）：

$$\beta = \ln\!\Bigl(\frac{1}{\tanh\!\bigl(\frac{\text{ripple\_dB}}{17.37}\bigr)}\Bigr), \qquad \gamma = \sinh\!\Bigl(\frac{\beta}{2N}\Bigr)$$

---

**Step 2** — 对每个位置 $k = 1, 2, \ldots, N$，计算两个辅助量：

$$a_k = \sin\!\Bigl(\frac{(2k-1)\pi}{2N}\Bigr), \qquad b_k = \gamma^2 + \sin^2\!\Bigl(\frac{k\pi}{N}\Bigr)$$

---

**Step 3** — 用递推公式逐个求出原型系数 $g_k$（梯形网络的归一化元件值）：

$$g_1 = \frac{2a_1}{\gamma}, \qquad g_k = \frac{4\,a_{k-1}\,a_k}{b_{k-1}\,g_{k-1}} \quad (k \geq 2)$$

> 直觉：$g_k$ 是一个"无量纲"版本的 L/C 值，它只由电气指标（纹波、阶数）决定，与频率和阻抗无关。

---

**Step 4** — 去归一化，把 $g_k$ 乘上实际频率 $\omega_c = 2\pi f_c$ 和阻抗 $R_0$，得到真实元件值：

**低通（LPF）**：
$$k \text{ 为奇数（电感位）} \Rightarrow L_k = \frac{R_0\,g_k}{\omega_c} \;\text{[H]} \qquad k \text{ 为偶数（电容位）} \Rightarrow C_k = \frac{g_k}{R_0\,\omega_c} \;\text{[F]}$$

**高通（HPF）** — L 和 C 互换、取倒数：
$$C_k = \frac{1}{g_k\,R_0\,\omega_c}, \qquad L_k = \frac{R_0}{g_k\,\omega_c}$$

**带通（BPF）** — 引入相对带宽 $\delta = BW/f_0$，每个原型元素拆分为一对串/并联 LC：
$$L_{\text{series},k} = \frac{R_0\,g_k}{\delta\,\omega_0}, \quad C_{\text{series},k} = \frac{\delta}{R_0\,g_k\,\omega_0} \qquad \text{（串联谐振对）}$$

---

**举例**：设计一个 5 阶低通滤波器，$f_c = 2.4\text{ GHz}$，ripple = 0.5 dB，$R_0 = 50\,\Omega$：

1. 算出 $\beta \approx 3.55$，$\gamma \approx 0.626$
2. 算出 $a_1, \ldots, a_5$ 和 $b_1, \ldots, b_5$
3. 递推得 $g_1\approx0.7563,\; g_2\approx1.3049,\; g_3\approx1.5773,\; g_4\approx1.3049,\; g_5\approx0.7563$
4. 去归一化：$L_1 = \frac{50 \times 0.7563}{2\pi \times 2.4\times10^9} \approx 2.51\text{ nH}$，$C_2 = \frac{1.3049}{50 \times 2\pi \times 2.4\times10^9} \approx 1.73\text{ pF}$，……

> **重点**：这个四步流程是**完全确定性的**（deterministic）——给定相同的 (N, ripple\_dB, fc, R0)，永远得到唯一一组正确的 LC 值。这正是为什么本论文让 LLM 只预测 N，其余交给公式自动完成。

---

## 2. 系统总体架构

RF-FilterLLM 分为三个阶段：

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Stage 1       │    │   Stage 2       │    │   Stage 3       │
│   数据引擎       │───▶│   QLoRA 微调     │───▶│   闭环智能体     │
│   Data Engine   │    │   Fine-Tuning   │    │   Closed-Loop   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

- **Stage 1 — 数据引擎**：自动生成大量"用户问题 + 标准答案"的对话数据，用于训练 LLM。
- **Stage 2 — QLoRA 微调**：用少量参数（0.047%）对预训练的 LLaMA 模型进行领域微调。
- **Stage 3 — 闭环智能体**：LLM 输出设计方案 → 公式计算 LC 值 → ADS 仿真验证 → 如果不满足指标，LLM 自动修正 → 循环。

---

## 3. 数据引擎：训练数据如何构建

### 3.1 参数空间采样

首先需要覆盖足够多样的设计场景。系统在以下范围内随机采样：

| 参数 | 采样范围 | 说明 |
|------|----------|------|
| 截止频率 fc | 0.1 – 30 GHz | 从低频到毫米波 |
| 阻带频率 fs | 1.2×fc – 5×fc | 保证 fs > fc |
| 纹波 ripple | 0.01 – 3 dB | 从极低到较高纹波 |
| 阻带衰减 La | 20 – 80 dB | 不同严格程度 |
| 特征阻抗 R0 | 25 – 100 Ω | 含标准 50Ω |

### 3.2 多频段滤波器变换

对于每一组 LPF 参数，系统会自动衍生出 HPF 和 BPF 版本：

- **HPF**：L 和 C 的角色互换，$C_k = \frac{1}{g_k \cdot R_0 \cdot \omega_c}$，$L_k = \frac{R_0}{g_k \cdot \omega_c}$
- **BPF**：需要额外参数（中心频率 f0、带宽 BW），每个原型元素变成一对 LC：
  - 串联 → 串联 LC
  - 并联 → 并联 LC

### 3.3 LLM 输出格式

LLM 的输出是一个 JSON 对象：

```json
{
  "filter_type": "chebyshev",
  "filter_band": "LPF",
  "ripple_db": 0.5,
  "fc": 2.4,
  "fs": 4.0,
  "R0": 50,
  "La_target": 40,
  "order": 5
}
```

**注意：这里没有 L、C 值！** LLM 只需预测 order（阶数）和规格参数，LC 值由公式计算。

### 3.4 多语言混合模板

为了让微调后的模型在中文、英文和混合语境下都能工作，系统使用三类模板：

- **中文**（60%）：`"请设计一个截止频率为 {fc} GHz 的切比雪夫低通滤波器..."`
- **英文**（15%）：`"Design a Chebyshev lowpass filter with cutoff frequency {fc} GHz..."`
- **混合**（25%）：`"设计一个cutoff frequency为 {fc} GHz的chebyshev LPF..."`

每个问题类型还有三个变体：
- **完整参数**（full-param）：给出所有参数
- **部分参数**（partial-param）：只给出部分参数，其余用默认值
- **追问** （followup）：多轮对话，先给出初始设计，再追问修改

### 3.5 动态意图补全（Dynamic Intent Completion）

当用户只给了部分参数时（比如只说"帮我设计一个 2.4 GHz 的低通滤波器"），系统不是拒绝服务，而是用合理默认值补全：

```
用户: "设计一个截止频率 2.4 GHz 的 LPF"
→ 系统自动补全: ripple=0.5dB, R0=50Ω, La=40dB, fs=1.5×fc
```

---

## 4. 三大数据增强管线

基础 SFT 数据只是"给定指标 → 输出参数"的简单映射。为了让模型具备更深层的工程推理能力，我们设计了三条增强管线。

### 4.1 PIR — 扰动诱导反思（Perturbation-Induced Reflection）

**核心思想**：让模型学会"哪里错了→怎么改"的推理能力。

**工作流程**：

1. **取一组正确设计**（ground truth）
2. **人为注入错误**（扰动），共四种策略：
   - `order_too_low`：将阶数减 1~2（模拟"阶数不够"的常见错误）
   - `fc_shifted`：将截止频率偏移（模拟"频率理解错误"）
   - `ripple_too_high`：将纹波放大 2~5 倍（模拟"纹波要求没控制好"）
   - `order_slightly_low`：阶数恰好少 1（模拟"边界情况误判"）
3. **用错误参数做仿真**，得到 S 参数（S11/S21 频率响应曲线）
4. **规则专家引擎**分析仿真结果，生成结构化反思文本：

```
反思：当前设计的阻带衰减仅为 25.3 dB，不满足 40 dB 的目标。
诊断：阶数 N=3 不足以提供足够的过渡带陡度。
修正方案：将阶数提升至 N=5，保持其他参数不变。
```

5. 最终生成的训练样本格式为：
   - **输入**：用户需求 + 错误设计的仿真结果
   - **输出**：反思分析 + 修正后的正确参数

> **关键**：反思文本是由规则引擎（而非 LLM）生成的，保证了逻辑严谨性和可控性。

### 4.2 BPP — 双向性能预测（Bidirectional Performance Prediction）

**核心思想**：让模型不仅能"正向设计"（需求→参数），还能"逆向理解"（参数→性能）。

BPP 包含两个子任务：

#### 4.2.1 正向预测（Forward Prediction）

给定一组 L、C 元件值，预测该电路的性能指标：

```
输入: "以下是一个 5 阶切比雪夫 LPF 的元件值：
       L1=3.2nH, C2=1.8pF, L3=4.1nH, C4=1.8pF, L5=3.2nH
       请分析其性能。"

输出: "预计截止频率 ≈ 2.4 GHz，阻带衰减 ≈ 42 dB@4.0 GHz，
       通带回波损耗 < -15 dB，通带纹波 ≈ 0.5 dB。"
```

#### 4.2.2 对比分析（Comparison）

给定两个设计方案，分析哪个更优：

```
输入: "方案A: 7阶, ripple=0.5dB, La=55dB
       方案B: 5阶, ripple=0.3dB, La=42dB
       哪个更好？"

输出: "两个方案均满足 La≥40dB 的目标。根据最小阶数原则，
       方案B 更优：使用更少的元件（5阶 vs 7阶）降低了成本和损耗，
       同时纹波更低（0.3 vs 0.5 dB），通带质量更好。"
```

> **最小阶数原则**：在满足性能要求的前提下，阶数越低越好。因为更少的元件意味着更低的成本、更小的尺寸和更低的插入损耗。

### 4.3 Curriculum Learning — 课程学习排序

**核心思想**：像教学一样，从简单到复杂地安排训练数据的顺序。

每条训练样本被赋予一个难度分数（0~1）：

$$D = 0.25 \times S_{\text{order}} + 0.20 \times S_{\text{extremity}} + 0.35 \times S_{\text{conv}} + 0.20 \times S_{\text{type}}$$

其中：

| 分量 | 含义 | 易（低分）→ 难（高分） |
|------|------|------------------------|
| $S_{\text{order}}$ | 阶数难度 | 低阶(3-4) → 高阶(9-10) |
| $S_{\text{extremity}}$ | 参数极端程度 | 常规参数 → 极端参数（极小纹波、极高衰减等）|
| $S_{\text{conv}}$ | 对话复杂度 | 单轮/完整参数 → 多轮/部分参数/追问修改 |
| $S_{\text{type}}$ | 滤波器类型 | LPF(0.0) → HPF(0.3) → BPF(0.7) |

然后将样本分为三个桶（easy / medium / hard），每个桶内随机打乱，最终按 easy→medium→hard 的顺序排列。

> **为什么 BPF 最难？** 因为带通滤波器涉及 5 个参数维度（fc_low, fc_high, f0, BW, δ），且每个原型元素要拆分成 LC 对，比 LPF/HPF 复杂得多。

---

## 5. 微调训练：QLoRA 技术详解

### 5.1 为什么不全量微调？

LLaMA-3 8B 模型有 80 亿参数。如果全量微调：
- 需要 > 160 GB 显存（FP16 下参数 16GB + 梯度 16GB + 优化器状态 128GB）
- 需要多张 A100/H100 GPU

而 QLoRA 只需 **单张 RTX 4090**（24GB 显存）即可完成训练。

### 5.2 QLoRA 的三个核心技巧

#### 5.2.1 NF4 量化（4-bit Normal Float）

将预训练权重从 16 位浮点数压缩到 4 位：
- 原始：每个参数占 16 bit → 8B 参数 ≈ 16 GB
- NF4：每个参数占 4 bit → 8B 参数 ≈ 4 GB
- 精度损失极小，因为 NF4 专门针对正态分布的权重值进行了优化

#### 5.2.2 LoRA 低秩适配器

不修改原始权重 W，而是添加一个小的"旁路"：

$$W' = W + \Delta W = W + B \cdot A$$

其中：
- W 是原始权重矩阵（冻结，不训练）
- A 的维度是 $d \times r$，B 的维度是 $r \times d$
- $r = 8$（秩），远小于 $d$（通常是 4096）
- 只训练 A 和 B，参数量仅为原始的 $2 \times r / d \approx 0.4\%$

本项目的具体配置：
- **目标模块**：`q_proj` 和 `v_proj`（注意力层的 Query 和 Value 投影）
- **LoRA 秩 r**：8
- **LoRA α**：16（缩放因子，控制 LoRA 的影响强度）
- **可训练参数**：3.83M（总参数的 0.047%）

#### 5.2.3 分页优化器

当显存不够用时（处理长序列时可能发生），自动将优化器状态从 GPU 显存卸载到 CPU 内存，处理完毕后再搬回来。

### 5.3 训练细节

| 配置项 | 值 |
|--------|-----|
| 基座模型 | LLaMA-3-8B-Instruct |
| 训练框架 | LLaMA-Factory |
| 训练 GPU | 单张 RTX 4090 (24GB) |
| 训练步数 | 3146 steps |
| Batch size | 4（梯度累积 4 步 → 有效 batch=16）|
| 学习率 | 2e-4，cosine decay |
| 训练时长 | 约 9.4 小时 |
| 最终 loss | ~0.28 |
| 量化精度 | NF4 (4-bit) |
| 序列长度 | 2048 tokens |

> **对比**：全量微调同样的模型至少需要 4×A100（约 8 万人民币），而本方案只需 1×RTX 4090（约 1.5 万人民币）。

---

## 6. 闭环智能体：LLM + 仿真器协作

### 6.1 为什么需要闭环？

单次 LLM 预测不一定完美。即使模型预测了正确的阶数，实际仿真时可能因为数值精度、寄生效应等原因导致性能不达标。闭环的意义在于：**让系统自己发现问题并修正**。

### 6.2 闭环流程

```
Step 1: 用户输入需求
         ↓
Step 2: LLM 预测设计参数 (order, ripple_db, fc, fs, R0, La)
         ↓
Step 3: filter_designer.py 计算 L/C 值 (确定性公式)
         ↓
Step 4: 生成 ADS 网表 → Keysight ADS 仿真
         ↓
Step 5: 提取 S 参数 (S11, S21 频率响应)
         ↓
Step 6: 评估是否满足指标
         ├── ✅ 满足 → 输出最终设计，结束
         └── ❌ 不满足 → 进入 Step 7
         ↓
Step 7: 将仿真结果反馈给 LLM，请求修正
         ↓
Step 8: LLM 输出调整后的参数 → 回到 Step 3
         (最多循环 5 次)
```

### 6.3 LLM 在闭环中能调整什么？

这是一个关键设计：LLM **只能**调整两个参数：

| 可调参数 | 调整方式 | 目的 |
|----------|----------|------|
| **order（阶数）** | ±1 或 ±2 | 增加阶数以提升滤波陡度 |
| **ripple_db（纹波）** | ×0.5 | 减小纹波以改善通带平坦度 |

LLM **不能**直接修改 LC 值！修改 order 后，LC 值由公式自动重新计算。

### 6.4 反思提示词设计

闭环中使用的反思提示词（reflection prompt）大致如下：

```
系统：你是一个 RF 滤波器设计专家。以下是上一轮设计的仿真结果：
- 目标阻带衰减: 40 dB
- 实际阻带衰减: 28.5 dB (❌ 不足)
- 目标通带回波损耗: < -15 dB
- 实际回波损耗: -18.2 dB (✅ 满足)

上一轮设计参数: order=4, ripple_db=0.5, fc=2.4, fs=4.0

请分析问题并输出修正后的设计参数。
```

LLM 的典型回复：

```json
{
  "filter_type": "chebyshev",
  "filter_band": "LPF",
  "order": 6,
  "ripple_db": 0.5,
  "fc": 2.4,
  "fs": 4.0,
  "R0": 50,
  "La_target": 40
}
```

### 6.5 ADS 仿真是什么？

**Keysight ADS**（Advanced Design System）是业界标准的射频电路仿真软件。它能精确模拟电路在不同频率下的行为。本系统调用 ADS 进行：

- **S 参数仿真（SP）**：计算电路在各频率点的传输和反射特性
- **S21**：传输系数 — 信号通过了多少（越接近 0 dB 越好在通带，越负越好在阻带）
- **S11**：反射系数 — 信号被反射了多少（越负越好，表示匹配良好）

---

## 7. 实验结果

### 7.1 整体准确率

| 模型 | LPF | HPF | BPF | 总体 |
|------|-----|-----|-----|------|
| GPT-4（零样本）| ~60% | ~55% | ~20% | ~45% |
| LLaMA-3-8B（基座）| 0% | 0% | 0% | 0% |
| LLaMA-3-8B + 朴素 SFT | 15.2% | 18.7% | 4.1% | 12.6% |
| **RF-FilterLLM（本文）** | **98.6%** | **98.2%** | **47.1%** | **83.4%** |

### 7.2 关键发现

1. **朴素微调反而有害**：不加数据增强的简单微调（12.6%）比 GPT-4 零样本（~45%）还差。这是因为模型过拟合到了训练集的模式，失去了推理能力。

2. **数据增强至关重要**：PIR + BPP + Curriculum Learning 是性能飞跃的关键。

3. **BPF 仍然困难**（47.1%）：带通滤波器的参数空间更复杂（5D vs 2D），但已远超其他方法。

4. **闭环显著提升**：通过最多 5 轮的仿真反馈，许多"差一点"的设计被成功修正。

### 7.3 消融实验

每个组件的贡献：

| 组件 | 移除后的准确率变化 |
|------|-------------------|
| PIR（反思数据） | -12.3% |
| BPP（双向预测） | -8.7% |
| Curriculum Learning | -5.1% |
| 闭环反馈 | -15.2% |

> 闭环反馈的影响最大，因为它补偿了单次预测中的误差。

---

## 8. 核心哲学：为什么不让 LLM 直接预测 LC 值？

这是本论文最精妙的设计选择，值得单独一章讨论。

### 8.1 直觉解释

假设你要设计一个 5 阶低通滤波器，需要 5 个元件值（例如 L1=3.2847 nH, C2=1.7592 pF, ...）。

**方案 A**（本文方案）：LLM 预测 `order=5`，然后公式计算出精确的 LC 值。
- LLM 的任务：从 {3, 4, 5, 6, 7, 8, 9, 10} 中选一个正确的整数 ✅
- 公式的任务：精确的浮点数运算 ✅

**方案 B**（直接预测 LC）：LLM 直接输出 L1=3.2847, C2=1.7592, ...
- LLM 的任务：预测 5~10 个高精度浮点数 ❌
- 问题：LLM 擅长语义理解和推理，不擅长精确数值计算

### 8.2 技术论证

1. **LLM 的本质是 token 预测**：它逐字符生成"3.2847"，每一位都可能出错。而阶数只是一个小整数，出错概率极低。

2. **LC 值有严格的物理约束**：gk 系数之间存在精确的数学关系。如果 LLM 独立预测每个值，很可能违反这些关系，导致设计失败。

3. **确定性计算保证正确性**：给定 (N, ripple_db, fc, R0)，LC 值有且仅有一组正确解。用公式计算百分之百正确。

4. **分工最优化**：
   - LLM 做它擅长的事：**工程判断**（需要多少阶？多少纹波够用？）
   - 公式做它擅长的事：**精确计算**（gk → L, C 的数学变换）

### 8.3 一句话总结

> **让 LLM 做"决策者"，让公式做"计算器"** — 各司其职，这就是本系统高效的根本原因。

---

## 9. 论文价值与意义

### 9.1 学术贡献

1. **首次将 LLM 应用于射频滤波器设计**：填补了 LLM + EDA 领域的空白。
2. **提出了"判断-计算分离"范式**：为其他工程设计领域的 LLM 应用提供了参考。
3. **系统化的数据增强策略**：PIR/BPP/Curriculum Learning 三条管线可推广到其他硬件设计任务。
4. **验证了小模型的潜力**：8B 模型在专业领域可以超越 GPT-4。

### 9.2 工业价值

1. **降低门槛**：射频滤波器设计传统上需要多年经验的工程师，本系统让初级工程师也能快速获得合理设计。
2. **降低成本**：单张消费级 GPU 即可训练，无需昂贵的计算集群。
3. **加速迭代**：闭环系统自动完成"设计→仿真→修正"循环，将原本数小时的人工工作压缩到分钟级。

### 9.3 局限性与未来方向

1. **BPF 准确率仍有提升空间**（47.1%）：可尝试更多 BPF 特有的训练数据。
2. **仅支持切比雪夫类型**：未来可扩展到巴特沃斯、椭圆等滤波器。
3. **未考虑寄生效应**：实际 PCB 版图的寄生电容/电感需要进一步建模。
4. **阶数上限**：目前支持到 10 阶，更高阶需要优化数值稳定性。

---

## 附录：关键代码文件速查

| 文件 | 功能 |
|------|------|
| `adsapi/filter_designer.py` | 滤波器设计核心 — gk 原型综合 + L/C 计算 |
| `make_sft_dataset_zhmix.py` | 生成中英混合 SFT 训练数据 |
| `generate_reflection_dataset.py` | PIR 数据增强 — 扰动 + 规则反思 |
| `generate_reverse_prediction_data.py` | BPP 数据增强 — 正向预测 + 对比分析 |
| `curriculum_learning.py` | 课程学习 — 难度评分 + 排序 |
| `sensitivity_analysis.py` | 灵敏度分析 — gk 扰动 + 元件排名 |
| `llm_ads_loop_iterative.py` | 闭环智能体 — LLM↔ADS 迭代循环 |
| `adsapi/llm_interface.py` | LLM 接口封装 |
| `adsapi/ads_engine.py` | ADS 仿真引擎接口 |
| `adsapi/post_processor.py` | S 参数后处理 + 指标评估 |

---

*本文档由项目自动生成，旨在帮助零基础读者理解 RF-FilterLLM 论文的全部技术细节。*
